CPU가 메모리에 접근하는 속도는 CPU의 연산속도보다 압도적으로 느림

### 저장 장치 계층 구조(memory hierachy)
- CPU와 가까운 저장장치는 처리 속도가 빠르고, CPU와 거리가 먼 저장장치는 처리 속도가 느림
- 처리 속도가 빠른 저장 장치는 일반적으로 저장 용량이 작고, 가격이 비쌈

즉, 낮은 가격대의 대용량 저장 장치를 원한다면 느린 속도는 감수해야 하고, 빠른 속도의 저장 장치를 원한다면 작은 용량과 비싼 가격은 감수해야 함

![](../../README_resources/Pasted%20image%2020240309232637.png)

저장 장치 계층 구조를 영문으로 나타내면 memory hierachy임 여기서 memory는 RAM이 아니라 일반적인 저장장치를 통칭하는 말

### 캐시 메모리
- CPU와 메모리 사이에 위치한, 레지스터보다 용량이 크고 메모리보다 빠른 SRAM 기반의 저장장치
- CPU의 연산속도와 메모리 접근 속도의 차이를 조금이나마 줄이기 위해 탄생
- "CPU가 매번 메모리에 왔다갔다하는 건 연산 속도에 비해 너무 오래 걸리니 메모리에서 CPU가 사용할 일부 데이터를 미리 캐시 메모리로 가지고 와서 쓰자"

![](../../README_resources/Pasted%20image%2020240309233635.png)
#### 계층적 캐시 메모리 
- 캐시 메모리는 하나가 아니며, CPU 내부에 위치해 있을 수도 있고 CPU 외부에 위치해 있을 수도 있음
- 용량 순 : L1 < L2 < L3
- 처리 속도 : L1 > L2 > L3

![](../../README_resources/Pasted%20image%2020240309235227.png)

![](../../README_resources/Pasted%20image%2020240309235318.png)

- L3 같은 경우에는 여러 코어가 공유하는 형태로 많이 사용한다고 함
- 공유해서 사용하는 경우에는 데이터 변경 시 해당 캐시를 공유하는 모든 코어가 변경 내용을 알게 하는 게 중요

- 아래 그림처럼 L1의 처리속도를 더 빠르게 만들기 위해 데이터만을 담고 있는 캐시, 명령어만을 담고 있는 캐시로 나눈 분리형 캐시를 사용하기도 함

![](../../README_resources/Pasted%20image%2020240310000239.png)

![](../../README_resources/Pasted%20image%2020240310000334.png)

- 캐시 메모리는 메모리보다 용량이 작음 -> 당연히 메모리의 모든 내용을 캐시에 저장하는 것은 불가능함
- 캐시는 CPU가 자주 사용할 법한 내용을 예측하여 저장함
	- 예측하여 저장한 내용을 실제로 CPU가 사용한 경우 : `캐시 히트`라고 부름
	- 그렇지 않은 경우 : `캐시 미스`라고 부름(메모리에 직접 다녀와야 하므로 성능이 떨어짐)
- 캐시 적중률 : 캐시 히트 횟수 / (캐시 히트 횟수 / 캐시 미스 횟수) 
	-> 요즘 캐시들은 대개 80%보다는 높음

### 참조 지역성의 원리
- CPU가 사용할 법한 데이터를 예측하는 방법, 원칙
- CPU가 메모리에 접근할 때의 주된 경향을 바탕으로 만들어짐
	1. CPU는 최근에 접근했던 공간에 다시 접근하려는 경향이 있음
	2. CPU는 접근한 메모리 공간 근처를 접근하려는 경향이 있음
		- 실제로 메모리 안에 서로 관련된 기능이나 데이터들은 모여 있음
