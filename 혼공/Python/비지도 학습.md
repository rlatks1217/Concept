### superivised Learning 과 반대되는 개념으로 맞춰야 하는 target value가 없는 것

- label없이 학습하기 때문에 당연히 label이 없는 것에 대한 문제를 해결할 수 있음

Ex) Clustering, Association Rule

**K-means**
1. 임의로 K개(설정해줘야 함)의 점을 중심점으로 배치한다.(일반적으로 무작위)
2. 각 데이터들에 대하여 가까운 중심점으로 할당한다.
3. 군집으로 지정된 데이터들을 기반으로 중심점을 업데이트한다.
4. 더이상 업데이트가 이뤄지지 않을 때까지 1~3과정을 반복한다.
![](../../README_resources/Pasted%20image%2020230706105047.png)

**Association Rule**
- 지지도 : itemSet의 빈도를 의미함
- 신뢰도 : 조건부확률

1. 전체 T라는 전체 데이터에서 지지도와 신뢰도가 연구자가 정해놓은 임의의 값보다 큰 itemSet을 추출하여 살펴본다
- Brute-force : 모든 연관규칙에 대해서 임의의 값보다 작은 것을 없애는 방식
-비싸고 시간도 오래 걸림
-당연히 신뢰도를 구하는 과정이 선행되어야 함
- Apriori 방식 : 연구자가 지정해놓은 지지도보다 빈도가 큰 아이템셋을 먼저 구분하고 규칙을 찾는 방식

`지지도의 특성`
- Anit-monotonicity : X가 Y의 서브셋일 때 Y의 지지도가 그 어떤 X의 지지도보다 항상 더 크다는 특성 => 즉, 자주 나오지 않는 데이터셋의 경우 서브셋까지 굳이 구할 필요없이 잘라버릴 수 있다.

### FP-tree
![](../../README_resources/Pasted%20image%2020230706180124.png)
이와 같이 특정 패턴에 대하여 횟수를 세서 가장 빈도가 많은 패턴을 찾는 것이 용이한 트리구조

- 횟수를 숫자로 나타내므로 비슷한 거리일 수록 압축해서 나타낼 수 있다는 장점이 있음

