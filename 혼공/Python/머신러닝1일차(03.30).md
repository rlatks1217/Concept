
- AI(인공지능, Artificial Intelligence) : 사람의 사고능력을 구현한 소프트웨어(시스템) 

1. Strong AI : 사람과 구별이 불가능한 AI => 이것을 만드는 것이 최종 목표지향점
2. (하지만 현실적으로 불가능함 => 만드는 방법조차 모르기 때문에)
3. weak AI : 특정분야에 국한된 AI(바둑, 자율주행, 챗봇 등등의 한 분야의 기능만 할 수 있는 AI) 

## Weak AI
- CS쪽에서 Data를 기반으로 학습해서 예측을 하도록 하는 것이 머신러닝임
- 지금까지 우리가 하고 있는 일반적인 프로그램은 Rule Based Program이라고 부름
- Rule Based Program (규칙 기반 프로그램) = > Explicit Program이라고도 부름
- 이런 프로그램은 데이터가 들어가면 로직 처리 후 해답이 나오는 구조임
- 하지만 머신러닝은 데이터와 해답이 같이 들어감 => 이에 대한 결과로 뽑아내는 것은 규칙성임
- 결과인 규칙성은 수식으로 나오게 됨(결국 수식을 결과로 얻게 된다고 할 수 있음)
- 이 수식을 Model이라고 할 수 있음
- 이 Model을 가지고 예측을 할 수 있음
- 이 수식을 만들기 위한 여러 알고리즘이 등장하기 시작함 => 머신러닝 기법이라고 함


## Machine Learning 기법
1. Regression Analasis(회귀 분석) : 통계쪽 개념에서 가져옴/일반적으로 이것을 배움
2. SVM(Support Vector Machine) : 
3. Decision Tree, Random Forest
4. KNN
5. Naive Bayes
6. Artificial Neural Network (인공신경망 : ANN) 
=> 이것을 발전시킨 것을 Deep Learning이라고 부름
- 즉, Deep Learning은 머신러닝의 한 분야임
- 다른 기법들과의 가장 큰 차이는 데이터의 형태가 다르다는 것
- 우리가 가지고 있는 데이터는 정형 데이터(데이터베이스의 담을 수 있는 형태의 데이터)임
-> 이런 데이터를 다룰 때는 일반 머신러닝 기법을 이용하는 것이 빠르고 효율적임
- 하지만 이미지, 자연어, 소리 등의 비정형 데이터는 대용량이며 형태가 정해져 있지 않기 때문에 일반 머신러닝 기법을 사용하면 정확도가 떨어짐
-> 그래서 이럴 때 Deep Learning을 사용함(더 정확함/하지만 복잡한 만큼 느림)
- 대부분의 예측은 빠르게 이뤄져야 하기 때문에 일반 머신러닝 기법을 사용함
------------------------------------------여기까지가 지도 학습-------------------------------------------
6. k-means(비지도 학습)
7. DBSCAN(비지도 학습)
8. Reinforcement Learning(강화학습) 

어떤 기법을 사용해야 하냐는 데이터의 형태에 달려있다고 할 수 있음


1. 데이터 + 해답(Label) => 프로그램 => 규칙성을 결과로 내놓음 : 지도학습
- 데이터마다 Label을 달아주는 Labeling 작업은 수작업으로 이뤄짐

1. 데이터만 => 프로그램 => 비슷한 데이터끼리 그룹으로 묶어줌 : 비지도학습
- 이 때 이것을 처리해주는 프로그램을 clustering model이라고 함

2. Label이 있는 데이터와 없는 데이터가 섞여 프로그램에 들어감 
=> 규칙성을 결과로 내놓음 : 준지도학습

4. 선택할 수 있는 행동(action)들 중에서 가장 최대의 보상(reward)을 가져다주는지 행동이 무엇인지 찾음 => 강화학습
- 알파고(바둑) : 강화학습이 사용된 대표적인 프로그램


## 지도학습
학습 데이터 + Label => 머신러닝 학습이 이뤄짐 => 그 결과로 Model(수식)이 만들어짐
- 단변량 : Label이 한 개인 경우(이것만 사용)
- 다변량 : Label이 여러 개인 경우(이건 안 씀) 

- 연속적인 숫자가 아니라 이산적인 숫자가 나오는 경우(어떤 부류인지가 결과로 나오는 경우)
=> Classification이라고 부름
- 연속적인 숫자가 나오는 경우
=> Regression이라고 부름(여기서의 Regression은 머신러닝 기법이 아니라 내 지도학습의 결과의 종류를 의미하는 용어임)

Ex)농어와 활어의 길이와 무게 데이터가 있다고 했을 때 특정 무게를 집어 넣었을 때 길이를 맞추게 만들면 회귀가 되는 것이고 무게, 길이를 같이 넣었을 때 농어인지 활어인지 맞추는 방식이라면 분류라고 할 수 있겠다.


## Regression(통계적 기법)
###### - 어떤 데이터에 대해 그 데이터에 영향을 주는 조건들의 영향력(가중치)을 이용해서 데이터에 대한 조건부 평균(특정 조건에 해당하는 데이터들의 평균)을 구하는 기법 

ex) 일반적으로 ''아파트 가격은 얼마인가요?'' 라고 했을 때 모든 아파트 가격들의 평균을 구하는 방식으로 데이터를 산출하여 대답할 수는 있다.
- 이렇게 단순히 평균을 구하는 것은 연도별 아파트 가격의 추이 같은 것을 구할 때는 의미가 있을 수 있지만 우리가 일반적으로 말하는 '강남의 아파트 가격은 얼마야?'와 같은 질문처럼 지역에 따라 위치에 따라 이 단순한 평균이라는 숫자는 누구는 수긍하지 못하는 값일 수 있음 -> 결국 이 때 이렇게 단순하게 구한 평균이라는 값은 의미없는 데이터가 됨

- 그럼 어떻게 의미 있게(누구나 수긍할 수 있게) 구할 수 있는가?
평수, 지역, 학군 등 집값에 영향을 미칠 수 있는 조건들을 가지고 계산하자 => 조건이 다르면 당연히 집의 가격이 달라지겠지
근데 각 조건들마다 집값에 영향을 미치는 정도가 다름
=> 아래 예시처럼 각 조건들의 영향력을 가미시켜서 수식으로 만듬
[ ex) y(집값) = (평수) x 7000 + (역세권) x 2000 + (학군) x 1000 ]
이런 식을 만들어 도출해낸 값을 실제로 강남의 집값의 평균을 계산한 결과에 가까워지도록 하는 계속 가중치(7000, 2000, 1000과 같은 숫자들)를 수정해나가는 과정을 회귀라고 함(강남의 집값을 예로 들면 '강남의 집값이 얼마야?' 라고 했을 때 이런 수식을 통해 구한 값이 실제 강남의 집값의 평균과 가깝게 하는 과정인 것이지 -> 실제로 지도학습에서는 훈련 데이터에 대한 계산을 먼저하고 계산한 값과 label로 나오는 데이터를 비교해가며 가중치를 수정하게 됨)

평균은 우리가 대표값으로 가장 많이 이용하는 값임
- 대표값 : 데이터 전체를 대표할 수 있는 값
- 또한, 대표값은 데이터를 가장 잘 표현하는 값을 말함 => 지금은 대표값 중 조건부 평균을 사용
- 평균 외에도 대표값으로 쓰이는 값의 종류가 많음(최소값, 최대값, 최빈값(가장 자주 등장하는 값)등) 

###### 즉, 회귀는 어떤 데이터(ex- 집값, 성적)에 대해 그 데이터에 영향을 주는 조건들의 영향력(가중치)을 이용해서 데이터에 대한 그 안의 데이터들을 가장 잘 표현하는 [1차 함수(직선) ]를 만드는 것을 말한다. 
모든 데이터를 가장 잘 나타내는 선이 2X+1이라고 하면 이 선을 찾을 때까지 가중치를 수정해가는 것임

Regression Model(수식)
- 독립변수 : 다른 변수에 의해 영향받지 않으며 결과(종속변수)에 영향을 주는 변수
- 종속변수 : 독립변수에 의해 결정이 되는 변수(결과) 

ex ) 연수기간, 공부시간에 따른 성적을 산출한다고 할 때 연수시간, 공부시간은 개별적인 데이터로 서로 다른 변수에 의해 영향을 받지 않는다. 반면 성적은 연수시간, 공부시간에 영향을 받기 때문에 종속변수라고 할 수 있다. (이 경우 독립변수는 2개임)

- 독립변수를 feature라고 부르며, 종속변수를 target, Label이라고 부름
-  연수기간, 공부시간이 바로 feature이고 Label(해답)이 target임


Regression Model에서 종속변수가 한 개라는 것은 이미 가정하고 있음
- 여기서 만약 독립변수가 1개라면
y(예측치) = x(독립변수가 들어오는 자리) x Beta Zero(가중치) + (보정치)
- 이 예측치가 현실세계에 들어맞아야 하기 때문에 약간의 보정하는 수치도 더해줌
- 이 식을 보기 쉽게 하기 위해 y = ax + b 라고 표현함 => 이렇게 바꾸고 보니까 직선 형태임 

즉, 내가 구하는 Model은 직선(1차 함수)이라고 할 수 있음 => 2차원이라고 할 수 있음
독립변수나 종속변수가 늘어나면 차원이 똑같이 하나씩 늘어남 

독립변수가 1개일 때 => y = ax + b 형태로 만들어짐
이 수식(Model)을 Classical Linea Regression Model이라고 함 

독립변수가 2개일 때 => y = ax1 +bx2 + c
이 땐, 수식이 선이 아니라 면 모양이 된다고 할 수 있음(이때 내가 구해야 하는 것들은 a, b, c임 => 회귀계수라고 함) 

Regression은 평균을 구하는 기법임
- 예를 들어 연봉데이터를 가지고 평균을 구하려고 하는데 삼성회장의 연봉이 데이터 중 하나로 있을 경우 평균이 의미가 없음(평균이 확 뛰어버리므로)
- 즉, 만약 데이터가 평균을 사용하기 힘든데이터라면 회귀모델 사용을 할지말지 고려해야 함
그래서 데이터를 파악하고 분석하는 것이 중요한 것
- 평균으로 사용하기 적합한 데이터의 예시 : 남성 성인의 키
-키의 분포를 그래프로 그려보면 정규분포 형태가 됨
- 평균으로 사용하기 힘든(평균을 구했을 때 그 값이 의미가 없는) 데이터의 예시 : 연봉
-편향이 있는 데이터(분포가 한쪽으로 치우쳐져 있는 데이터)는 사용하기 힘듬


Regression(회귀)라는 이름이 붙은 이유 
- 1800년대 찰스 다윈의 "종의 기원"(진화론) 등장
- 이것을 보고 출발한 프란시스 골던의 우성 인자를 이용한 조금 더 나은 인류에 대한 우생학 등장
- 연구 결과 키가 큰 사람들의 후손은 점점 작아지고 작은 사람들의 후손은 점점 커진다 
=> 즉, 시간이 지날수록 평균에 가까워지고 있음 
=> 그래서 발표한 논문에 이름이 Regression toward Mean임 => 여기서 따옴


## 회귀계수 구하기
y=ax + b 를 머신러닝에서는 y= wx+b라고 표현함
- w는 weight를 의미
- b는 bias를 의미 

1. 일단 선(1차함수)을 아무거나 그려놓고(실제로는 처음에 이 아무 직선이란 것을 그리는 공식같은 게 있을 것임) 해당 그래프가 분포를 잘 표현하고 있는지 확인해야 함
HOW? '오차'(Error)라는 개념을 사용(오차(Error) : 실제값에서 추정값을 뺀 값)
- t(해답) - y(예측치)가 오차라고 할 수 있음(적은 게 당연히 좋음)
- 각 점에 대해서 t-y(오차)를 구한 것이므로 당연히 결과는 개별적인 값일 거야(결과값이 여러 개란 거지)
- 근데 여러 개면 좋은지 안 좋은지 판단하기 힘듬 그래서 각 점의 오차들을 하나로 만들기 위해 가장 쉬운 방법인 오차의 합을 구하기 시작함
- 이때 이 오차의 합이 작은 값이면 좋은 것이다 라고 판단할 수 있는 거지
- 근데 더할려고 보니 음수값도 있을 경우 그냥 생각없이 더했을 땐 오히려 합을 감소시킬 우려가 있음
- 그래서 오차의 제곱을 하고(무조건 양수가 되니까) 그것의 평균을 구함(제곱의 합이라는 값은 너무 크니까 이 모든 오차의 제곱을 대표할 수 있는 평균을 구한 것) => 이렇게 구한 평균을 평균제곱오차(Mean Squared Error)라고 부름 

이 평균제곱오차가 우리 모델이 좋은지 안 좋은지 판단하는 기준이 됨 그래서 이 평균제곱오차를 구하는 식을 loss function이라고 부름
즉, 우리가 만든 모델이 좋은지 안 좋은지 판단하는 기준이 되는 식을 loss function이라고 하고 그 loss function으로 MSE를 사용하고 있는 것임(1차 함수의 경우 mse를 loss funtion으로써 사용하면 좋기 때문에) 

![](../../README_resources/Pasted%20image%2020230331095457.png)
이렇게 평균제곱오차 식을 통해서 구합 값을 loss라고 하고 이게 작아야 좋은 것임 

일반식 : 시그마 들어가있는 식처럼 수학적인 식으로 바꾼 것을 의미함

n = 데이터의 갯수
시그마는 for문이라고 생각하자 (i부터 n까지) 

n과 t, x들은 이미 정해져 있어서 바꿀 수 없는 값들임 -> w,b를 바꿔가면서 최적값에 가까워지게 되는 것임 

loss를 결정하는 식을 그래프로 그리면 2차 함수임
loss가 가장 작으려면 w, b가 포함된 해당 2차 함수의 미분한 결과가 그래프의 최솟값 위치일 때 오차가 최소화가 된다고 할 수 있다(이 위치에서는 미분한 결과가 0이 됨 -> 미분값이 0이면 오차가 최소가 되겠구나!)


![](../../README_resources/Pasted%20image%2020230331095525.png)
- w(x값) - 임의의 수(학습률이라고 부름)x미분값을 하면 최솟값에 가까워짐(학습률을 곱하는 이유는 미순값이 너무 크기 때문/너무 크면 w가 변하는 폭이 너무 커질 수 있고 그렇게 되면 계속 최소지점을 지나치게 되어 영영 최소지점을 못 찾게 되는 상황이 생길 수 있기 때문)
- 그래서 미분하고 위의 식을 계산하는 과정을 0이 될 때까지 반복문으로 반복함
- 임의의 수를 곱하는 이유는 미분값이 너무 크기 때문이라고 함 

즉, 학습데이터의 열과 한번에 Model(수식)이 반환값으로 내놓은 예측값들과 인자로 작성했던 실제 해답 데이터들을 loss function을 이용하여 비교하고 w, b를 바꿔가면서 오차를 줄여가는 것이지(이 과정을 학습이라고 함)



데이터 + Label을 Model에 집어넣음 => 예측치를 반환하려면 데이터 수만큼(들어가는 데이터가 4행 1열이면 4번) y = wx +b라는 수식을 계산하는 반복문을 돌아야 함 --> 만약 데이터가 많다면 어마어마하게 느려짐 

![](../../README_resources/Pasted%20image%2020230331095545.png)
행렬 곱을 이용하면 한번에 계산할 수가 있음(집어넣는 데이터를 행렬 형태로 바꿔줘야 함) -> w 역시 1행 1열의 행렬형태로 만들어줘야 함 

그래서 집어넣는 데이터가 행렬곱연산이 가능한 형태여야 하므로 내부에서 넘파이 형태로 넘겨주는 것임 

b는 왜 그냥 냅두냐? b는 변수이긴 한데 이 과정에서는 w처럼 계속 바뀌는 애가 아니라 고정적일 것이므로 이 계산과정에서는 상수로 봄 -> 그래서 왜 그냥 냅두는데? 상수를 더한다는 얘기는 결국 공통적인 애가 더해진다는 얘기인데 말했듯이 numpy array형태는 브로드캐스팅이 가능함 즉, 브로드캐스팅이 되서 계산되므로 따로 행렬형태로 만들어줄 필요가 없는 거지


이 학습 과정을 직접 파이썬 코드로 구현하는 것은 가장 안 좋음(여러가지 이유로 성능도 안 좋고 일단 짜기 빡셈)
그래서 라이브러리를 사용 (tensorflow안에 있는keras) 

##### 우리가 사용할 Keras안의 Model의 동작방식
![](../../README_resources/Pasted%20image%2020230331095603.png)
우리가 학습데이터를 2차원numpy배열 형태로 Model에 집어넣음(실제로 인자로  Label을 같이 써주긴 하지만 Model에는 들어가지 않는다/비교 후 갱신 과정까지 있는 로직이 담긴 함수의 인자로는 같이 들어가겟지)
input Layer(Flatten)의 역할 : X에 들어갈 데이터를 받는 역할
- input Layer안의 동그라미 : 각각 feature(독립변수를 의미하는 열 하나) 하나하나를 받는 애(동그라미 하나를 Node라고 표현함) 독립변수가 3개라면 동그라미도 3개 있어야 함
- 즉, Node는 feature의 개수만큼 있음 => Node의 수 = feature의 수

outPut Layer(Dense)의 역할 : 연산을 수행하고 예측치를 내보냄
- w는 이 Layer 안에 있음(Layer가 만들어지면 feature 수에 따라서 갯수를 알아서 계산하여 가지고 있음)
- 실제 행렬곱을 하고 특정 동그라미 안에 예측 데이터를 담음
- 이 동그라미 역시 예측치(Matrix형태)의 갯수만큼 있어야 함(지금은 2차원 numpy배열 하나로 결과가 나오니까 1개만 있으면 되는 거야)
- 이 동그라미가 연산하는 주체이며 들어온 모든 데이터에 대해 연산 후 예측치를 내보냄 

예측치가 나오면 loss function을 이용해서 오차의 평균을 구하고 이것의 미분값을 구하여(접선의 기울기를 구하여) w, b를 갱신하는 과정이 이뤄짐
=> Optimizer라는 알고리즘을 이용하여 이 과정을 진행함
- 이때 Optimizer 중 대표적인 Optimizer가 GD(Gradient Descent) 

최종적으로 이렇게 갱신까지 하는 일련의 과정 1번을 1epoch라고 함 

conda install tensorflow : tensorflow 설치(버전 명시 안해주면 자동으로 최신 버전으로 설치해줌) 

처음 평균 그래프에서 임의의 점은 특정 공식에 의해 랜덤틱하게 찍히게 된다고 함
결국 에폭수와 학습률을 잘 정해주는 것이 중요함 

X데이터를 W와 곱하고 b를 더해주는 과정 이외에 다른 과정 없이 그냥 내보내는 것을 linear라고 함 그래서 activation =linear라고 하면 연산 이외의 다른 과정은 하지 않고 그냥 예측치를 내보내겟다는 의미가 되는 것임