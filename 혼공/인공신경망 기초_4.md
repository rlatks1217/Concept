### RNN
- 우리는 하나의 공이 있다고 할 때 그것이 어디로 움직일지 예측할 수 있을까?
- 공이 해당 위치에 도달하기 1초전의 위치를 알고 1초전 위치까지 도달하기 위해 2초전 위치를 알고..
이런 식으로 이전의 위치를 모두 알고 있다면 어디로 움직일지 대충 예측할 수 있음
- 그렇기 때문에 연속적인 데이터를 다뤄야 한다고 볼 수 있음


- RNN : 입력과 출력을 시퀀스 단위로 처리하는 시퀀스 모델
- 시퀀스란? 시계열 데이터와 같이 연속적인 데이터를 의미함 / Ex)  문장은 단어의 시퀀스라고 할 수 있다. 
- 이렇게 문장과 같이 단어의 순서에 따라 의미가 달라지는 시퀀스 데이터를 입력으로 받고 출력 또한 시퀀스 데이터로 내보내는 모델들을 시퀀스 모델이라고 함 RNN도 그 중 하나임
Ex) 감성 분석, 문서 분류, 질의 응답, 스팸 메일 분류 등에 사용되는 모델임

**Imbedding** : 자연어처리에서 사람이 쓰는 자연어를 기계가 이해할 수 있도록 숫자 형태인 vector로 바꾸는 과정을 말함(벡터화 혹은 Word Imbedding이라고 도 함)

**vector** : 토큰마다 공간을 표현한 숫자로 구성된 배열로 만드는 것 /  `문장을 벡터화한다` : 문장에서 각 단어들을 컴퓨터가 알아먹을 수 있는 숫자 배열로 표현한 걸 모아 놓은 것을 말함
- 단어 하나를 [0.2, 0.5, ...]와 같이 숫자의 배열로 만든 것을 하나의 벡터라고 부르는 것
- 학습이 진행될 때 입력층의 노드의 갯수는 한 벡터의 요소값의 수와 같음(= 차원의 수라고 많이들 표현함 / [1, 2, 3] 같은 경우 3차원임) 즉, 입력값은 단어 하나 단위로 들어가는 것임(벡터화가 이뤄지니까 벡터화가 이뤄진 결과 배열(list)의 각 요소값들이 노드마다 들어가는 것이지)
- 문장은 [ [2, 1, 1], [13, 3, 5] ]  과 같이 표현할 수 있을 것임


**token** : 데이터를 작은 단위로 나누는 과정에서 나눠지는 개별적인 요소를 의미함
Ex) "Hello, how are you?"라는 문장을 토큰화하면 "Hello", ",", "how", "are", "you", "?"와 같은 토큰으로 분할될 수 있음

##### Sequence Modeling 설계기준
- 문장과 같이 입력값의 길이가 계속 바뀔 수 있으므로 가변 길이를 처리할 수 있어야 함
- 긴 문장에서 앞부분에 나온 내용을 토대로 빈칸과 같은 것에 어떤 단어가 올 지 예측할 수 있어야 함
- 들어오는 정보들(단어)의 순서를 유지할 수 있어야 함
- 순차적으로 정보가 들어온다고 할 때 모두 같은 가중치가 적용되어야 함

### 순환 신경망(Recurrent Neural Network, RNN)
- 이때까지 했던 신경망들은 모두 은닉층에서 활성화함수로 비선형변환을 하고 출력층의 방향으로만 학습을 했음 (이와 같은 신경망들을 피드 포워드 신경망(Feed Forward Neural Network)라고 함)
- 하지만 그렇지 않는 신경망들이 있는데 RNN도 그 중 하나임


**선형결합** : RNN에서 선형 결합은 현재 시간 단계의 입력 값과 이전 시간 단계의 hidden_state를 가중치와 곱한 후 더하는 과정

- RNN에서 은닉층의 노드는 다음 층으로 값을  활성화함수를 적용시켜서 내보내게 됨(입력층에서는 입력값을 활성화함수를 적용해서 다음 층으로 내보내는 게 아님)
- 은닉층의 각 노드는 hidden_state(은닉상태)라는 변수를 가지고 있어 여기에다가 이전 시점의 입력값을 기억하는 것마냥 저장할 수 있음(그래서 이 노드들을 메모리 셀 또는 RNN셀이라고 부름)
- 그래서 이전 층으로부터 값을 받는 현재 층의 노드에서는 이전 시점의 값을 기억하고 있으므로 이를 이전 시점의 값과 현재 입력값을 선형결합하여 받게 됨(이 과정은 입력층에서 은닉층으로 값이 전달될 때부터 일어나는 과정임)
- 이 때 이전의 값을 은닉상태값이라고 함
- 물론 처음 학습을 시작한 시점엔 이전 값이 없으므로 선형결합이 이뤄지지 않음
- 단어 단위로 가중치 조정(즉, 단어 단위로 일단 예측치를 내보내 보는 거임 이후 loss를 통해 단어 단위로 가중치를 조정하게 되겠지)

RNN의 각 노드는 두 개의 주요 가중치를 가지고 있음
1. 입력에 대한 가중치(W_x): 현재 시간 단계의 입력과 곱해지는 가중치
2. 이전 출력에 대한 가중치(W_h): 이전 시간 단계의 값(hidden_state)과 곱해지는 가중치
--> 각각 가중치를 적용시키고 덧셈하는 게 바로 선형결합