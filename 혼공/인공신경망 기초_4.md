### RNN
- 입력과 출력을 시퀀스 단위로 처리하는 시퀀스 모델
- 시퀀스란? 시계열 데이터와 같이 연속적인 데이터를 의미함 / Ex)  문장은 단어의 시퀀스라고 할 수 있다. 
- 이렇게 문장과 같이 단어의 순서에 따라 의미가 달라지는 시퀀스 데이터를 입력으로 받고 출력 또한 시퀀스 데이터로 내보내는 모델들을 시퀀스 모델이라고 함 RNN도 그 중 하나임
Ex) 감성 분석, 문서 분류, 질의 응답, 스팸 메일 분류 등에 사용되는 모델임

**Imbedding** : 자연어처리에서 사람이 쓰는 자연어를 기계가 이해할 수 있도록 숫자 형태인 vector로 바꾸는 과정을 말함(벡터화 혹은 Word Imbedding이라고 도 함)

**vector** : 토큰마다 공간을 표현한 숫자로 구성된 배열로 만드는 것 /  `문장을 벡터화한다` : 문장에서 각 단어들을 컴퓨터가 알아먹을 수 있는 숫자 배열로 표현한 걸 모아 놓은 것을 말함
- 단어 하나를 [0.2, 0.5, ...]와 같이 숫자의 배열로 만든 것을 하나의 벡터라고 부르는 것
- 학습이 진행될 때 입력층의 노드의 갯수는 한 벡터의 요소값의 수와 같음(= 차원의 수라고 많이들 표현함) 즉, 입력값은 단어 하나 단위로 들어가는 것임(벡터화가 이뤄지니까 벡터화가 이뤄진 결과 배열(list)의 각 요소값들이 노드마다 들어가는 것이지)
- 문장은 [ [2, 1, 1], [13, 3, 5] ]  과 같이 표현할 수 있을 것임


**token** : 데이터를 작은 단위로 나누는 과정에서 나눠지는 개별적인 요소를 의미함
Ex) "Hello, how are you?"라는 문장을 토큰화하면 "Hello", ",", "how", "are", "you", "?"와 같은 토큰으로 분할될 수 있음

### 순환 신경망(Recurrent Neural Network, RNN)
- 이때까지 했던 신경망들은 모두 은닉층에서 활성화함수로 비선형변환을 하고 출력층의 방향으로만 학습을 했음 (이와 같은 신경망들을 피드 포워드 신경망(Feed Forward Neural Network)라고 함)
- 하지만 그렇지 않는 신경망들이 있는데 RNN도 그 중 하나임

단어 단위로 가중치 조정(즉, 단어 단위로 일단 예측치를 내보내 보는 거임 이후 loss를 통해 단어 단위로 가중치를 조정하게 되겠지)
처음에는 현재값이랑 조합할 이전 데이터 없음
이전 시점의 데이터를 가지고 현재값이랑 조합
각 노드는 hidden_state라는 변수를 가지고 있어 여기에다가 이전 시점의 입력값을 기억하는 것마냥 저장할 수 있음

- RNN에서 은닉층의 노드는 다음 은닉층으로 값을  활성화함수를 적용시켜서 내보내게 됨
- 이때 이전 층으로부터 값을 받는 현재 층의 노드에서는 이전 시점의 값을 기억하고 있으므로 이를 이전 시점의 값과 현재 입력값을 선형결합(RNN에서 선형 결합은 현재 시간 단계의 입력 값과 이전 시간 단계의 hidden_state를 가중치와 곱한 후 더하는 과정)하여 받게 됨 