
**퍼셉트론** : 인공신경망의 구성요소로서 다수의 값을 입력받아 각각 가중치를 곱하고 하나의 값으로 합친 후 계단함수와 같은 활성화함수를 통해 값을 출력하는 프랑크 로젠블라트(Frank Rosenblatt)가 1957년에 제안한 초기 형태의 인공 신경망의 모양
- 퍼셉트론은 이진분류기임 즉, 두 가지 카테고리로 분류하는 모델
- 퍼셉트론 하나만 있을 때 단층 퍼셉트론이라고 부름
- 결국 인공신경망이라는 것도 수학적으로 봤을 땐 수식이므로 알고리즘이라고 표현할 수도 있는 것

결국 최적의 가중치를 찾는 것이 학습의 최종 목표
1. 처음에는 랜덤하게 아무 값이나 가중치로 넣고 학습을 시작함
2. 얼마나 잘 예측했냐는 loss function을 가지고 판단
3. loss를 w로 미분(즉, 오차제곱의 합을 미분)하여 어느 정도로 조정을 할지에 대한 값을 정할 때 사용함 -> 미분값이 포함된 공식을 통해서 조정할 값을 정하고 가중치를 조정하게 됨(경사하강법)

근데 이렇게 한번의 가중치 조정을 위해서 모든 데이터에 대하여 loss를 계산하는 건 너무 비효율적이지 않음?? 물론 모든 데이터를 다 계산해야 하는 만큼 느리기도 하겠지
--> 그래서 전체를 작은 단위로 쪼개서 그 작은 뭉치 단위로 계산하기 시작함(이게 미니배치 학습임)
- Batch Gradient Descent : 모든 데이터를 때려박아가며 학습시키는 방법
- Stochastic Gradient Descent(SGD) : 전체 중 1개의 데이터만 뽑아서 학습시키는 방법

17분부터
### 미분을 구하는 방법


