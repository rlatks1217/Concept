**퍼셉트론** : 인공신경망의 구성요소로서 다수의 값을 입력받아 각각 가중치를 곱하고 하나의 값으로 합친 후 계단함수와 같은 활성화함수를 통해 값을 출력하는 프랑크 로젠블라트(Frank Rosenblatt)가 1957년에 제안한 초기 형태의 인공 신경망의 모양
- 퍼셉트론은 이진분류기임 즉, 두 가지 카테고리(0, 1)로 분류하는 모델
- 퍼셉트론 하나만 있을 때 단층 퍼셉트론이라고 부름
- 결국 인공신경망이라는 것도 수학적으로 봤을 땐 수식이므로 알고리즘이라고 표현할 수도 있는 것
- 일반적으로 각각의 가중치를 곱하고 합치는 것까지의 과정을 포함하는 게 퍼셉트론임(여기에 비선형 변환이 일어난 후 다음 층으로 전달)

단일 퍼셉트론은 수식으로 봤을 때 직선의 형태임 하지만 이런 직선으로는 복잡한 문제를 풀 수 없음 -> 복잡한 계산(ex - XOR(배타적 논리합))은 중간에 계산을 한 번 더 거치면(이 과정이 진행되는 게 바로 훗날의 hidden layer) 가능하다는 것을 알아냄

- 즉, AND + NAND를 통해 XOR과 같은 복잡한 연산이  가능해짐
- 그런데 AND와 NAND도 각각 다르게 생긴 가중치로 연산이 일어나는 것을 알 수 있음(가중치(변수) 자체가 다르니까 당연히 계산식이 다르다고 봐야지) 즉, 두 가지 수식이 있고 해당 수식들에서 나온 결과를 합하여 새로운 결과를 도출해내게 됨
- 하지만 결과적으로 이 수식들도 큰 과정의 한 부분이기 때문에 모두 하나의 수식으로 묶어서 표현이 가능함(그래서 처음에 Model은 하나의 수식이라고 했던 것)

- **이해할 땐 '노드마다 각기 다른 수식이 있고 해당 수식들은 결국 전체에서는 부분적인 과정이므로 부분들을 모두 묶어 하나의 수식으로 표현이 가능한 것이다. ' 라고 이해하면 될 듯**
- 이런 식으로 여러 노드 뿐 아니라 이 여러 노드들이 포함되어 있는 hidden layer 늘려서 현재 알고 있는 인공신경망의 형태가 됨

1. AND
- 말 그대로 A, B가 모두 1인 경우에만 1을 반환
![](Pasted%20image%2020230717185127.png)
2. NAND(Not AND)
- AND의 반대 즉, A, B가 모두 0인 경우에만 1을 반환
![](Pasted%20image%2020230717185140.png)
3. OR
- A, B 중 하나라도 1이면 1을 반환
![](Pasted%20image%2020230717185235.png)


**XOR**
- A, B 중 하나'만' 1이어야 1을 반환하는 이상한 경우임
![](Pasted%20image%2020230717185322.png)
이 경우 각 데이터들의 경계를 그래프로 나타내려고 하면 아래 보이는 것처럼 하나의 직선으로는 경계를 나눌 수가 없음
![](Pasted%20image%2020230717191218.png)
그럼 어떻게 할까? 일단 휘게 만들자 => 활성화함수 사용(이게 비선형 변환임)

**Colaboratory 코드 참고(XOR)**
