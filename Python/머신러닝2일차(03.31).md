
## Regression
- 예측을 위한 수식(Model)을 만드는 게 목적인 기법
- 예측치를 연속적인 숫자의 형태(Regression)나 어느 부류의 속하는지(Classification)로 알려줌
- 바로 위의 줄의 Regression은 연속적인 숫자의 형태를 의미하는 Regression

##### 1. Linear Regression Model
- 연속적인 숫자를 예측치로 내놓은 모델
- 특정 숫자를 해당 Model에 집어넣으면 특정 숫자로 예측치를 내놓음
- feature의 갯수에 따라 simple Linear Regression Model(독립변수 1개)/simple Linear Regression Model(독립변수 여러 개) 
- 종속변수의 경우에는 단변량 즉, 1개인 것을 가정함(무조건 1개라는 얘기)
- 현실 세계에서는 독립변수가 1개인 경우는 거의 없다(거의 예외없이 독립변수가 여러 개임)

(그림1 첨부)
- w가 Matrix형태가 되었을 때 1x1여야 행렬곱연산이 가능함
- w(가중치)는 output Layer을 만들면 이미 있음(갯수 또한 들어가는 학습데이터에 따라 자동으로 계산해줌) + b도 원래 이 Layer 안에 있음(정확히는 이 Layer안에 있는 동그라미 안에 있음)

- 예를 들어 오존량이 종속변수라고 했을 때 오존량에 영향을 미치지 않는 변수도 데이터에 포함되어 있을 수 있음(이런 변수는 독립변수가 아님)
- 그래서 해당 변수와 종속변수가 어느 정도의 상관관계가 있는지 계산하는 식(Model)이 있음 => 이 식을 제공해주는 라이브러리가 있음

##### 정규화
- feature 간의 스케일이 많이 차이나게 될 경우 스케일 큰 feature가 전체 판단을 좌지우지하는 꼴이 된다.
- 모든 데이터 포인트가 동일한 정도의 스케일(중요도)로 반영하기 위해 정규화가 필요함
- 최대값 1, 최소값 0 사이의 값으로 변환
- feature와 target간에도 스케일 맞춰줘야 제대로 된 예측이 가능하므로 독립변수가 1개여도 target과 feature을 정규화를 해줘야 함

##### 2. Logistic Regression Model
- 이 안에서 예측치의 종류가 또 2가지로 나뉨
- Binary Classification(Binary : 2진 = 둘 중 하나라는 의미)
- Multinomial Classification(분류가 여러 개)

사실은 W - ((alpha)x미분값)과 같이 b에 대한 갱신과정도 있음(지금은 안 배움) => 편미분 개념 등장
