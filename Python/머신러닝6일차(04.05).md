##### 복습
- Linear Regression : 종속변수가 연속적인 숫자값
- 종속변수가 변함(이진(이항) 분류의 형태로)
- simoid라는 수학식을 이용하여 model을 살짝 바꿈 => Logistic Regression(binary classification)
- 종속변수가 또 변함(다중 분류(한 분류를 class라고 말함)의 형태로 바뀜)
- 이진분류를 여러 개 모아서 Multimomial Classification을 해결
- model은 one-hot(정답 분류은 1로 표시 아닌 것은 0으로 표시) 처리가 된 target과 예측값(예측한 분류은 1로 표시 아닌 것은 0으로 표시)을 비교하면서 학습하게 됨
- 확률값이 나오는데 각 class별 확률값을 결과로 보여줌(ex) 0.6, 0.3, 0.1

여기까지는 정형 데이터를 대상으로 하는 머신러닝이었음

- 이제 이미지, 자연어, 소리 등과 같은 비정형 데이터를 대상으로 한 예측을 해보려고 함
- 하지만 기본적인 머신러닝 알고리즘으로는 잘 안 됨(학습이 안 되는 것은 아니지만 정확도가 떨어짐)
- 그래서 알고리즘을 바꾸자 뭐로? ANN(인공신경망)
- Layer(hidden Layer)를 더 많이 만들면 좋다 라는 얘기를 했었음
- keras model을 근간으로 생각하면 쉬움
- 즉, 사람이 실제로 생각하는 것처럼 model을 구성해보자 라는 생각에서 input Layer과 output Layer 사이에 hidden Layer(unit, node)라는 놈들을 여러 개 더 만들어보잔 얘기

이것을 DNN(Deep Neural Network)이라고 함 => 이것을 좀 더 보완해서 마케팅적 측면에서 이름을 조금 바꾼 것이 바로 Deep Learning임 ex) 알파고

그래서 사람들이 DNN을 이용해서 이미지를 학습하면 좋을 것이라고 생각함 그런데 문제가 생김 => 사람은 기본적으로 공간지각능력을 가지고 있음/하지만 컴퓨터는 아님 그래서 방향 달라진 똑같은 물체를 완전히 다른 물체라고 인식함 => 일일이 데이터를 다 넣어줘야 함(하지만 하나의 물체라도 모든 경우를 따져가며 데이터를 다 학습시켜줘야 함 => 학습도 힘들 뿐더러 그 많은 데이터를 다 집어넣어주는 것도 힘듬)

이미지는 기본적으로 3차원data임 => DNN은 행렬곱을 위해 데이터를 2차원 형태로 넣어줘야 함
이것을 해결하기 위한 알고리즘인 CNN이 나오게 됨

코렙 접속 후
1. Ram CPU --> GPU로 변경
2. 드라이브 mount 시키기(드라이브 폴더 클릭)

## Image 파일에 대해 기억해야 하는 것

##### 좌표계
일반적으로 우리는 데카르트 좌표계를 사용
이미지는 다른 좌표계를 사용함 (y, x)로 표기

이미지는 pixel data로 나오는데 첫번째가 세로, 두번째가 가로 형태로 나오게 됨

- 이미지는 각 pixel에 가로 세로 color(rgb)로 구성
- png는 투명도라는 구성도 있기 때문에 더 풍부한 색깔을 표현할 수 있음
- 흑백이미지는 rgb의 각 요소들을 다 더한 후 평균을 구해서 평균을 픽셀의 각 자리(3칸)에다가 넣어서 구성하는 방식임

다중 분류의 경우 softmax를 사용하고 이때 output Layer는 어떤 클래스인지를 분류해주기 때문에 '분류기'라는 표현을 쓴다.
(그림 5참고)

## CNN(Convolutional Neural Network)
- 기존의 DNN의 구조가 전체 구조에서 뒤편을 차지하게 됨(Flatten이 input data를 받지 않음)
- convolution Layer : 합성곱이라는 연산을 하는 층 => relu라는 함수를 이용해서 연산 후 내보냄(여러개 나올 수 있음)
- pooling Layer : 뭔가 처리를 하고 내보냄
- 즉, DNN 구조는 맨 뒤편에 있는 것이고 그 Flatten Layer에 들어가기 전에 input data를 바꿔주는 역할이 앞 Layer들에서 수행됨(쉽게 말해 이미지 데이터가 input data로 들어간다고 했을 때 학습의 적합한 형태로 바꾸는 과정이 선행된다는 얘기)
- 이런 과정이 선행되었을 때 더 잘 학습된다는 걸 알게 되어 이 구조를 사용하기 시작함
- CNN에서 hidden Layer는 많아야 1개 나옴

(그림 6 첨부)

(그림 7 첨부)
- convolution(합성곱) 연산 : Filter(kernel이라고도 함)를 Image Data랑 맞춰보고 각 자리의 숫자끼리 곱하고 합산함 
=> 1칸(칸은 내가 임의로 설정해줄 수 있고 stride라고 부름/ stride가 크면 클수록 이미지 데이터의 크기가 작아질 수 밖에 없음) 이동 => 같은 연산을 반복함(여기서 더이상 갈 칸이 없으면 1칸 밑으로 내려감) => 다시 왼쪽에서부터 연산하면서 이동함

이것을 여러번 할 경우 이미지의 크기가 점점 작아지고 너무 작아지면 나중에는 알아볼 수 없게 작아져버린다고 함 => 다음 convolution연산이 이뤄지기 전에 zero padding이라는 것 사용하여 강제로 크기를 늘릴 수 있음(늘어난 공간은 모두 0으로 채우게 됨(0은 있어도 의미없는 값이므로 이렇게 채워도 상관없음))

filter는 여러개 있을 수 있음(그래서 filter의 갯수만큼 합성곱 결과(이미지)가 나오게 됨 즉, 여러 개의 특징만 뽑은 변형본을 만들게 됨 => 학습량이 많아지게 되는 것/대신 각각의 이미지 사이즈는 원본보다는 작음(여러 case를 각각 원본 데이터 가지고 하는 것보다는 효율적)) => 이 여러 filter를 통해 데이터들을 늘려서많은 학습량을 만들게 쓰게 됨 

CNN의 합성곱이라는 것은 결국 해당 사진이 가진 특징들만 가지고 학습하게 하면 훨씬 효율적이지 않을까? 라는 생각에서 나오게 된 것임

##### 위에 써있듯이 이미지 사이즈가 줄어들긴 하는데 많이 줄지는 않음 / 그에 비해 filter에 의해 새로 생기는 이미지는 기하급수적으로 늘고 있는 형태임
- 이 문제를 해결하기 위해 Image size를 억지로 줄임! 이 때 이용하는 것이 pooling Layer임
- CNN은 1번의 epoch마다 W나 b를 수정하는 것 뿐만 아니라 filter를 개선시키는 과정도 포함한다.
(정확히는 filter를 구성하는 값을 바꿈)

- pooling 중 MAX pooling이란 것을 사용함
(그림 9 첨부)
filter를 통해 걸러져서 만들어진 변형본은  featureMap이라고 함 => 이것을 pooling(Max pooling)함 / pooling하는 거름망 같은 것도 kernel이라고 부름
해당 kernal의 stride(이동할 칸 수)도 지정할 수 있고 kernal size(줄일 크기)도 지정해줄 수 있음(마찬가지로 featureMap의 차원과 같은 차원이어야 함)
MAX pooling : 거름망에 속해있는 값 중 가장 큰 값만 가져와서 kernal 사이즈에 맞게 이미지 크기를 줄임

이렇게 크기를 줄이면 그림이 온전한 상태로 남아 있나요? => yes

##### 정리하면 여기까지의 과정은 학습하는 과정이 아니라 학습을 하기 전의 해당 이미지에 대한 특성을 추출하는 단계라고 할 수 있음 => Feature Extraction이라고 함