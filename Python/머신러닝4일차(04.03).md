- 기존에는 독립변수가 1개였음 => 그래서 y = WX +b 였음
- 이 때 X가 독립변수, W는 가중치, b는 보정치 그리고 y가 예측값


##### 여기서 독립변수가 3개라면? 
![](Pasted%20image%2020230403181615.png)
- 한 행마다 식에 대입하는 방식으로 반복문을 돌려서 각각의 예측값을 구할 수는 없는 노릇이니 행렬곱을 이용해서 예측값을 한번에 뽑아냄
- 여기서 예측값은 n행 1열의 값이 나와야 하므로 W는 (독립변수의 갯수)행 x 1의 형태여야 함
- 결국 예측값은 n행 1열의 데이터가 나오게 됨
- (w1, w2, w3는 각 독립변수의 가중치임)

## Logistic Regression
- 종속변수의 형태가 바뀜(연속적인 숫자의 형태에서 true/false와 같이 분류의 형태로 바뀜)
- ex) 공부시간과 연수기간에 따른 합/불 여부
- 여기서 합/불 여부를 0과 1로 나타냄
- 이러한 종속변수의 형태를 이진 분류의 형태라고 함(binary Classification)
![](Pasted%20image%2020230403181636.png)
1. 종속변수의 형태만 달라졌는데 Model을 바꿔야 돼? 라는 생각에서 처음엔 Linear Regression으로 해결하려고 노력함 => 결론적으로 안 됐음(왜인지는 안 배움)
2. 그럼 어떻게 해야 되는데? => 연구 끝에 하나의 수학식을 들고 옴
3. 이 수학식이 Sigmoid임 => 그림 참고 / 이것을 잘 이용하면 기존의 Model을 응용하여 제대로 된 예측이 가능해짐
- 자연상수의 차수위치에 기존의 우리가 배웠던 Model(수식)을 집어넣어서 새로운 Model을 만들게 됨
- 이렇게 기존의 model을 응용해서 만든 새로운 이진 분류를 위한 Model을 Rogistic이라고 함
4. 기존의 Model은 제대로 만들어진 Model인지 확인하기 위해 loss function으로 MSE를 사용했었음
5. 하지만 이제는 Model이 달라졌음 
=> loss function으로 사용되는 수식 역시 다시 만들어야 함
=> 이렇게 해서 만들어진 수식을 crossEntropy라고 함

새로운 Model(Rogistic)은 예측치를 0~1의 값으로 반환 => 반환된 예측값은 0과 1중 1(true)이 될 확률을 의미함
즉, 위의 예시에서 Model 자체는 합/불 자체를 알려주기보단 합격할 확률을 알려준다고 할 수 있음

## Evaluation(평가)
![](Pasted%20image%2020230403181657.png)
1. 방법
- 실제로는 400개의 row가 있다고 하면 이 전체를 가지고 학습에 이용하는 것이 아님
- 그럼 어떻게 함? 가지고 있는 데이터를 일반적으로 7:3이나 8:2 비율로 자름 => 일부분으로 학습을 하고 나머지 부분으로는 평가를 함
ex)학습한 데이터를 가지고 예측을 하게 하면 당연히 올바르게 예측을 할 것임/하지만 이것은 제대로 된 평가라고 할 수 없음(model이 학습하지 않은 유사한 다른 데이터를 가지고 해야 제대로 된 평가라고 할 수 있음)
- 즉, Test data와 Training data로 나눈다는 얘기임 평가는 Test data로 1번만 이루어짐
- 이 평가는 최종적으로 Model이 어느 정도로 알고 있는지 확인하기 위한 평가임

- 이와는 다르게 학습을 하면서 학습이 제대로 이뤄졌는지(잘 배웠는지) 평가를 진행할 수도 있음(이 때 사용되는 데이터를 validation data이라고 함) / 여기서 이뤄지는 평가는 위의 평가랑은 다른 의미의 평가임 => 쉽게 말해서 올바른 방향으로 학습하고 있는지 확인하는 용도라고 보면 됨
1. 평가기준 (Matric이라고 함)
- 평가기준(Matric)은 여러가지가 있을 수 있음
- 그 중에 어떤 기준(수식)을 사용할 지는 Confusion Matrix를 보고 결정함 즉, 식을 만들기 위해 Confusion Matrix를 만듬

##### 가장 흔하게 사용하는 Matric : Accuracy
![](Pasted%20image%2020230403181717.png)
- true로 예측한 경우를 Positive라고 함
- false로 예측한 경우를 Negative라고 함
- TP : 원래 True가 답인데 올바르게 예측한 경우
- TN : 원래 false가 답인데 올바르게 예측한 경우
즉, 맞춘 경우에 T가 붙음 그러므로 식이 의미하는 바(Accuracy = 식)는 모든 경우에 있어서 제대로 맞춘 비율을 의미함
- 데이터가 편향되어 있는 경우에는 Accuracy로 측정할 수 없음 왜? 밑의 예제 확인
ex) 희귀병을 가지고 있는 사람을 판단하는 Model을 만든다고 했을 때 임의로 무조건 0(앓고 있지 않다.)을 예측값으로 반환하는 Model로 만들었다고 가정해보자 => 이 경우 실제로는 희귀병을 가지고 있는 사람을 맞추지 못함에도 불구하고 Accuracy로 측정했을 때는 정확도가 높게 나오게 됨 즉, 여기선 Accuracy라는 기준으로는 잘 만든 Model인지 제대로 평가할 수가 없는 것임
